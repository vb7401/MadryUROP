{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "madry_starter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4LgFm17ZiX_",
        "colab_type": "text"
      },
      "source": [
        "# MadryLab UROP Starter Project\n",
        "\n",
        "Code for robust optimization algorithm as discussed in https://arxiv.org/abs/1706.06083. Written in PyTorch by Vivek Bhupatiraju."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdzVIUIhZzN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQiSrP8ikbd_",
        "colab_type": "text"
      },
      "source": [
        "## Implementing ResNet-18 for CIFAR\n",
        "\n",
        "Uses code from: https://github.com/kuangliu/pytorch-cifar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqHUUJZQZiDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, in_planes, planes, stride=1):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_planes != self.expansion*planes:\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "            nn.BatchNorm2d(self.expansion*planes)\n",
        "        )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = F.relu(out)\n",
        "    return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "  expansion = 4\n",
        "\n",
        "  def __init__(self, in_planes, planes, stride=1):\n",
        "      super(Bottleneck, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(planes)\n",
        "      self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "      self.bn2 = nn.BatchNorm2d(planes)\n",
        "      self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "      self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "      self.shortcut = nn.Sequential()\n",
        "      if stride != 1 or in_planes != self.expansion*planes:\n",
        "          self.shortcut = nn.Sequential(\n",
        "              nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "              nn.BatchNorm2d(self.expansion*planes)\n",
        "          )\n",
        "\n",
        "  def forward(self, x):\n",
        "      out = F.relu(self.bn1(self.conv1(x)))\n",
        "      out = F.relu(self.bn2(self.conv2(out)))\n",
        "      out = self.bn3(self.conv3(out))\n",
        "      out += self.shortcut(x)\n",
        "      out = F.relu(out)\n",
        "      return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_blocks, num_classes=10):\n",
        "      super(ResNet, self).__init__()\n",
        "      self.in_planes = 64\n",
        "\n",
        "      self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(64)\n",
        "      self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "      self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "      self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "      self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "      self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "  def _make_layer(self, block, planes, num_blocks, stride):\n",
        "      strides = [stride] + [1]*(num_blocks-1)\n",
        "      layers = []\n",
        "      for stride in strides:\n",
        "          layers.append(block(self.in_planes, planes, stride))\n",
        "          self.in_planes = planes * block.expansion\n",
        "      return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "      out = F.relu(self.bn1(self.conv1(x)))\n",
        "      out = self.layer1(out)\n",
        "      out = self.layer2(out)\n",
        "      out = self.layer3(out)\n",
        "      out = self.layer4(out)\n",
        "      out = F.avg_pool2d(out, 4)\n",
        "      out = out.view(out.size(0), -1)\n",
        "      out = self.linear(out)\n",
        "      return out\n",
        "\n",
        "def ResNet18():\n",
        "  return ResNet(BasicBlock, [2,2,2,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5htsVaVr0QF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fff0084a-6381-4f20-e831-2e2521ab9f51"
      },
      "source": [
        "# test\n",
        "net = ResNet18()\n",
        "y = net(torch.randn(1,3,32,32))\n",
        "print(y.size())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2bPj7UEsQ6z",
        "colab_type": "text"
      },
      "source": [
        "## Training ResNet-18 with CIFAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUoI4iKYQBIg",
        "colab_type": "text"
      },
      "source": [
        "### Setting Up Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "691bSBRk7yON",
        "colab_type": "text"
      },
      "source": [
        "Setting up train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDTyFquEsY7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c01823ed-da99-4aca-8b60-6aa824ca476c"
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0\n",
        "start_epoch = 0\n",
        "\n",
        "# prepare train and test splitss\n",
        "\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvq_1iGvNiQ4",
        "colab_type": "text"
      },
      "source": [
        "Training + Testing Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbnlRvpUNhwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = ResNet18()\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    start = time.time()\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        print(batch_idx, end=\" \")\n",
        "\n",
        "        # progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "        #     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    \n",
        "    end = time.time()\n",
        "\n",
        "    print()\n",
        "    print(\"Time Elapsed for Training: \" + str(end - start))\n",
        "    print()\n",
        "  \n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    start = time.time()\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            print(batch_idx, end=\" \")\n",
        "\n",
        "            # progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "            #    % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    \n",
        "    acc = 100.*correct/total\n",
        "    best_acc = max(best_acc, acc)\n",
        "    end = time.time()\n",
        "\n",
        "    print(\"Accuracy for Epoch \" + str(epoch) + \": \" + str(acc))\n",
        "    print(\"Best Accuracy: \" + str(best_acc))\n",
        "    print(\"Time Elapsed for Training: \" + str(end - start))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfrlV6R0QE3q",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x-FxKMHOyuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(start_epoch, start_epoch+200):\n",
        "    train(epoch)\n",
        "    test(epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}